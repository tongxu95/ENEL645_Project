{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# About this notebook  \n","This notebook is developed for the Kaggle competition \"Cassava Leaf Disease Classification\" and referenced [starter code](https://www.kaggle.com/yasufuminakama/cassava-resnext50-32x4d-starter-training/) shared by other competitors.\n","\n","For the loss functions we referenced [this workbook](https://www.kaggle.com/piantic/train-cassava-starter-using-various-loss-funcs/notebook).\n","\n","For the Test-Time Augmentation we referenced [this workbook](https://www.kaggle.com/japandata509/ensemble-resnext50-32x4d-efficientnet-0-903)."],"metadata":{"papermill":{"duration":0.0219,"end_time":"2021-04-13T19:23:14.521412","exception":false,"start_time":"2021-04-13T19:23:14.499512","status":"completed"},"tags":[],"id":"oqho9hi8RDmX"}},{"cell_type":"markdown","source":["# Data Loading"],"metadata":{"papermill":{"duration":0.02087,"end_time":"2021-04-13T19:23:14.563014","exception":false,"start_time":"2021-04-13T19:23:14.542144","status":"completed"},"tags":[],"id":"_Y1DsPKVRDmb"}},{"cell_type":"code","source":["import os\n","\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt"],"metadata":{"papermill":{"duration":0.027884,"end_time":"2021-04-13T19:23:14.61144","exception":false,"start_time":"2021-04-13T19:23:14.583556","status":"completed"},"tags":[],"id":"-27HJ8UURDmc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir('../input/cassava-leaf-disease-classification')"],"metadata":{"papermill":{"duration":0.030354,"end_time":"2021-04-13T19:23:14.662681","exception":false,"start_time":"2021-04-13T19:23:14.632327","status":"completed"},"tags":[],"id":"oU9_M1huRDmd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n","test = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n","val = pd.read_csv('../input/valid/val_data.csv')\n","label_map = pd.read_json('../input/cassava-leaf-disease-classification/label_num_to_disease_map.json', \n","                         orient='index')\n","display(train.head())\n","display(test.head())\n","display(label_map)"],"metadata":{"papermill":{"duration":0.404669,"end_time":"2021-04-13T19:23:15.089548","exception":false,"start_time":"2021-04-13T19:23:14.684879","status":"completed"},"tags":[],"id":"d5FR4iGkRDmd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Directory settings"],"metadata":{"papermill":{"duration":0.023037,"end_time":"2021-04-13T19:23:15.135369","exception":false,"start_time":"2021-04-13T19:23:15.112332","status":"completed"},"tags":[],"id":"v26HtS1lRDme"}},{"cell_type":"code","source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","import os\n","\n","OUTPUT_DIR = './'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","TRAIN_PATH = '../input/cassava-leaf-disease-classification/train_images'\n","TEST_PATH = '../input/cassava-leaf-disease-classification/test_images'\n","OUTPUT_PATH = '../input/models/'\n","VAL_PATH = '../input/valid/'"],"metadata":{"papermill":{"duration":0.030924,"end_time":"2021-04-13T19:23:15.189263","exception":false,"start_time":"2021-04-13T19:23:15.158339","status":"completed"},"tags":[],"id":"_5b_hjdZRDme","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Explore Your Data"],"metadata":{"papermill":{"duration":0.022936,"end_time":"2021-04-13T19:23:15.236004","exception":false,"start_time":"2021-04-13T19:23:15.213068","status":"completed"},"tags":[],"id":"6UYbLELMRDmf"}},{"cell_type":"code","source":["counts = train.groupby('label').count()\n","counts"],"metadata":{"papermill":{"duration":0.038,"end_time":"2021-04-13T19:23:15.296862","exception":false,"start_time":"2021-04-13T19:23:15.258862","status":"completed"},"tags":[],"id":"7NwUwEOXRDmg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.label.hist(bins=range(label_map.shape[0]+1))\n","plt.grid(False)\n","plt.xlabel('Cassava Leaf Disease Classification Labels')\n","plt.ylabel('Label Frequency')\n","plt.title('Cassava Leaf Disease Classification Class Distribution')"],"metadata":{"papermill":{"duration":0.225609,"end_time":"2021-04-13T19:23:15.545898","exception":false,"start_time":"2021-04-13T19:23:15.320289","status":"completed"},"tags":[],"id":"1e0Yyh9LRDmg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The classes are highly skewed, thus, I will apply StratifiedKFold for model selection. Refer to class CFG for the configuration (chosen parameters)."],"metadata":{"papermill":{"duration":0.024993,"end_time":"2021-04-13T19:23:15.596652","exception":false,"start_time":"2021-04-13T19:23:15.571659","status":"completed"},"tags":[],"id":"zEWPd4WMRDmh"}},{"cell_type":"code","source":["# get min and max from a sample image\n","file_name = train['image_id'][0]\n","file_path = f'{TRAIN_PATH}/{file_name}'\n","image = plt.imread(file_path)\n","print('Min: {}, Max: {}'.format(image.min(), image.max()))"],"metadata":{"papermill":{"duration":0.076033,"end_time":"2021-04-13T19:23:15.699123","exception":false,"start_time":"2021-04-13T19:23:15.62309","status":"completed"},"tags":[],"id":"1-OM1EYRRDmh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show 30 sample images from each class\n","classes = []\n","for i in range(5):\n","    classes.append(train[train['label'] == 0])\n","    \n","for i in range(5):\n","    df = classes[i]\n","    indexes = np.random.choice(df.shape[0], size=30, replace=False)\n","    file_names = df['image_id'].values\n","    plt.figure(figsize = (24, 18))\n","    plt.suptitle('Label: %d' %i, y = 0.9)\n","    for j, idx in enumerate(indexes):\n","        plt.subplot(5, 6, j+1)\n","        file_name = file_names[idx]\n","        file_path = f'{TRAIN_PATH}/{file_name}'\n","        image = plt.imread(file_path)\n","        plt.imshow(image)"],"metadata":{"papermill":{"duration":27.548316,"end_time":"2021-04-13T19:23:43.272247","exception":false,"start_time":"2021-04-13T19:23:15.723931","status":"completed"},"tags":[],"id":"ud4-zOErRDmi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After running the above cells a few times, it can be seen that the training set is fairly noisy. Some of images for healthy leaves (class 4) appears diseased: the leaves are withered, and/or showed a yellowish color with brown spots. Some images did not show leaves at all."],"metadata":{"papermill":{"duration":0.265199,"end_time":"2021-04-13T19:23:43.811301","exception":false,"start_time":"2021-04-13T19:23:43.546102","status":"completed"},"tags":[],"id":"S3Fkhen3RDmi"}},{"cell_type":"markdown","source":["# CFG\n","Class CFG contains configuration parameters."],"metadata":{"papermill":{"duration":0.268748,"end_time":"2021-04-13T19:23:44.348764","exception":false,"start_time":"2021-04-13T19:23:44.080016","status":"completed"},"tags":[],"id":"dM46hD5nRDmj"}},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    print_freq=100\n","    num_workers=4\n","    size=256 # please change size to 224 when using vit or deit models\n","    model_name='resnext50_32x4d' # ['resnext50_32x4d', 'tf_efficientnet_b3_ns', 'vit_small_patch16_224', 'vit_base_patch16_224', 'deit_base_patch16_224']\n","    optimizer='Adam' # ['Adam', 'AdamW', 'AdamP', 'Ranger']\n","    scheduler='CosineAnnealingWarmRestarts' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n","    criterion='LabelSmoothingLoss' # ['CrossEntropyLoss', 'SymmetricCrossEntropyLoss', 'LabelSmoothingLoss', 'FocalLoss', FocalCosineLoss', 'TaylorCrossEntropyLoss']\n","    epochs=20\n","    factor=0.2 # ReduceLROnPlateau\n","    patience=4 # ReduceLROnPlateau\n","    eps=1e-6 # ReduceLROnPlateau\n","    T_max=10 # CosineAnnealingLR\n","    T_0=10 # CosineAnnealingWarmRestarts (# number of iterations before the first restart)\n","    smoothing=0.5\n","    lr=1e-4\n","    min_lr=1e-6\n","    batch_size=32\n","    weight_decay=1e-6\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    train=False\n","    inference=True\n","    enet_weights=[0, 1, 2, 3, 4]\n","    enet_name='tf_efficientnet_b3_ns'"],"metadata":{"papermill":{"duration":0.295452,"end_time":"2021-04-13T19:23:44.913776","exception":false,"start_time":"2021-04-13T19:23:44.618324","status":"completed"},"tags":[],"id":"5lYAIYshRDmk","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Installation"],"metadata":{"papermill":{"duration":0.269015,"end_time":"2021-04-13T19:23:45.449936","exception":false,"start_time":"2021-04-13T19:23:45.180921","status":"completed"},"tags":[],"id":"t6aUEJ5ORDmk"}},{"cell_type":"code","source":["# !pip install adamp\n","# !pip install pytorch-ranger"],"metadata":{"papermill":{"duration":0.282546,"end_time":"2021-04-13T19:23:46.001854","exception":false,"start_time":"2021-04-13T19:23:45.719308","status":"completed"},"tags":[],"id":"bAAhwEvSRDml","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Library"],"metadata":{"papermill":{"duration":0.293579,"end_time":"2021-04-13T19:23:46.563887","exception":false,"start_time":"2021-04-13T19:23:46.270308","status":"completed"},"tags":[],"id":"-EgJyWGMRDml"}},{"cell_type":"code","source":["# ====================================================\n","# Library\n","# ====================================================\n","\n","import math\n","import time\n","import random\n","from contextlib import contextmanager\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedKFold\n","\n","from tqdm.auto import tqdm\n","\n","import cv2\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.optim import Adam, AdamW\n","# from adamp import AdamP\n","# from pytorch_ranger import Ranger\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n","\n","from albumentations import (\n","    Compose, Normalize, Resize, RandomResizedCrop, HorizontalFlip, VerticalFlip, ShiftScaleRotate, Transpose\n","    )\n","from albumentations.pytorch import ToTensorV2\n","\n","import sys\n","sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","# setting device on GPU if available, else CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"papermill":{"duration":5.433352,"end_time":"2021-04-13T19:23:52.268366","exception":false,"start_time":"2021-04-13T19:23:46.835014","status":"completed"},"tags":[],"id":"T6wwRMSYRDmm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Utils"],"metadata":{"papermill":{"duration":0.280716,"end_time":"2021-04-13T19:23:53.027235","exception":false,"start_time":"2021-04-13T19:23:52.746519","status":"completed"},"tags":[],"id":"UPp4YuLJRDmn"}},{"cell_type":"code","source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    return accuracy_score(y_true, y_pred)\n","\n","\n","@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    LOGGER.info(f'[{name}] start')\n","    yield\n","    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n","\n","\n","def init_logger(log_file=OUTPUT_DIR+'train.log'):\n","    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = init_logger()\n","\n","\n","def seed_torch(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_torch(seed=CFG.seed)"],"metadata":{"papermill":{"duration":0.314464,"end_time":"2021-04-13T19:23:53.636242","exception":false,"start_time":"2021-04-13T19:23:53.321778","status":"completed"},"tags":[],"id":"vbp31-ziRDmn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Stratified K Folds"],"metadata":{"papermill":{"duration":0.275379,"end_time":"2021-04-13T19:23:54.19156","exception":false,"start_time":"2021-04-13T19:23:53.916181","status":"completed"},"tags":[],"id":"MCC9hCFtRDmo"}},{"cell_type":"code","source":["folds = train.copy()\n","Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['label'])):\n","    folds.loc[val_index, 'fold'] = int(n)\n","folds['fold'] = folds['fold'].astype(int)\n","display(folds.head())"],"metadata":{"papermill":{"duration":0.315128,"end_time":"2021-04-13T19:23:54.786049","exception":false,"start_time":"2021-04-13T19:23:54.470921","status":"completed"},"tags":[],"id":"AltyTDctRDmo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(folds.groupby(['fold', 'label']).size())"],"metadata":{"papermill":{"duration":0.296977,"end_time":"2021-04-13T19:23:55.358779","exception":false,"start_time":"2021-04-13T19:23:55.061802","status":"completed"},"tags":[],"id":"nGX4pFDARDmp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"papermill":{"duration":0.277866,"end_time":"2021-04-13T19:23:55.917079","exception":false,"start_time":"2021-04-13T19:23:55.639213","status":"completed"},"tags":[],"id":"7ih-zEmORDmp"}},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","# Dataset inherit from torch.utils.data.Dataset which leverage parallel processing and pre-fetching in order reduce data loading time as much as possible\n","# Dataset object loads data into memory and a DataLoader fetch data from a Dataset and serves the data up in batches\n","class TrainDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.file_names = df['image_id'].values\n","        self.labels = df['label'].values\n","        # f = some_func() is analogus to def f.. \n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        file_name = self.file_names[idx]\n","        file_path = f'{TRAIN_PATH}/{file_name}'\n","        image = cv2.imread(file_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        if self.transform:\n","            augmented = self.transform(image=image)\n","            image = augmented['image']\n","        label = torch.tensor(self.labels[idx]).long()\n","        return image, label\n","    \n","\n","class TestDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.file_names = df['image_id'].values\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        file_name = self.file_names[idx]\n","        # validation set\n","#         file_path = f'{TRAIN_PATH}/{file_name}'\n","        # test submission\n","        file_path = f'{TEST_PATH}/{file_name}'\n","        image = cv2.imread(file_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        if self.transform:\n","            augmented = self.transform(image=image)\n","            image = augmented['image']\n","        return image"],"metadata":{"papermill":{"duration":0.298562,"end_time":"2021-04-13T19:23:56.494771","exception":false,"start_time":"2021-04-13T19:23:56.196209","status":"completed"},"tags":[],"id":"S0jRRcPyRDmq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = TrainDataset(train, transform=None)\n","\n","for i in range(1):\n","    image, label = train_dataset[i]\n","    plt.imshow(image)\n","    plt.title(f'label: {label}')\n","    plt.show() "],"metadata":{"papermill":{"duration":0.922435,"end_time":"2021-04-13T19:23:57.696773","exception":false,"start_time":"2021-04-13T19:23:56.774338","status":"completed"},"tags":[],"id":"euCs6iqTRDms","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Augmentation and Normalization"],"metadata":{"papermill":{"duration":0.62402,"end_time":"2021-04-13T19:23:58.614564","exception":false,"start_time":"2021-04-13T19:23:57.990544","status":"completed"},"tags":[],"id":"L3R5zHR5RDms"}},{"cell_type":"code","source":["# ====================================================\n","# Transforms\n","# ====================================================\n","def get_transforms(*, data):\n","    \"\"\"\n","    Define an data standardization and augmentation pipeline for training and validation set\n","    \"\"\"\n","    if data == 'train':\n","        return Compose([\n","            #Resize(CFG.size, CFG.size),\n","            RandomResizedCrop(CFG.size, CFG.size),\n","            Transpose(p=0.5),\n","            HorizontalFlip(p=0.5),\n","            VerticalFlip(p=0.5),\n","            ShiftScaleRotate(p=0.5),\n","            Normalize(\n","                mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225],\n","            ),\n","            # PyTorch Tensor is similar to numpy array but can run on GPUs\n","            ToTensorV2(),\n","        ])\n","\n","    elif data == 'valid':\n","        return Compose([\n","            Resize(CFG.size, CFG.size),\n","            Normalize(\n","                mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225],\n","            ),\n","            ToTensorV2(),\n","        ])"],"metadata":{"papermill":{"duration":0.294404,"end_time":"2021-04-13T19:23:59.196149","exception":false,"start_time":"2021-04-13T19:23:58.901745","status":"completed"},"tags":[],"id":"1Y58_vAVRDmt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n","\n","for i in range(1):\n","    image, label = train_dataset[i]\n","    plt.imshow(image[0])\n","    plt.title(f'label: {label}')\n","    plt.show() "],"metadata":{"papermill":{"duration":0.469427,"end_time":"2021-04-13T19:23:59.938478","exception":false,"start_time":"2021-04-13T19:23:59.469051","status":"completed"},"tags":[],"id":"GcNBrGhSRDmt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MODEL"],"metadata":{"papermill":{"duration":0.278337,"end_time":"2021-04-13T19:24:00.491899","exception":false,"start_time":"2021-04-13T19:24:00.213562","status":"completed"},"tags":[],"id":"30QKH-wvRDmu"}},{"cell_type":"code","source":["# ====================================================\n","# MODEL\n","# ====================================================\n","# nn.Module serves as base class for all neural network modules\n","class CustomEfficientNet(nn.Module):\n","    def __init__(self, model=CFG.model_name, pretrained=True):\n","        super().__init__()\n","        self.model = timm.create_model(model, pretrained=pretrained)\n","        n_features = self.model.classifier.in_features\n","        # apply a linear transformation to the incoming data from the last convolutional layer to get output of target_size\n","        self.model.classifier = nn.Linear(n_features, 5)\n","\n","    # Defines the computation performed at every call (should be overriden by all subclasses)\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x\n","    \n","    \n","class CustomResNext(nn.Module):\n","    def __init__(self, model=CFG.model_name, pretrained=True):\n","        super().__init__()\n","        self.model = timm.create_model(model, pretrained=pretrained)\n","        n_features = self.model.fc.in_features\n","        self.model.fc = nn.Linear(n_features, 5)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x\n","\n","    \n","class CustomDeit(nn.Module):\n","    def __init__(self, model_name=CFG.model_name, pretrained=False):\n","        super().__init__()\n","        self.model = torch.hub.load('facebookresearch/deit:main', model_name, pretrained=False)\n","        self.n_features = self.model.head.in_features\n","        self.model.head = nn.Linear(self.n_features, 5)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x\n","\n","class CustomVit(nn.Module):\n","    def __init__(self, model_name=CFG.model_name, pretrained=False):\n","        super().__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained)\n","        n_features = self.model.head.in_features\n","        self.model.fc = nn.Linear(n_features, 5)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"papermill":{"duration":0.297671,"end_time":"2021-04-13T19:24:01.069493","exception":false,"start_time":"2021-04-13T19:24:00.771822","status":"completed"},"tags":[],"id":"pQhNMXQmRDmu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loss Function"],"metadata":{"papermill":{"duration":0.278912,"end_time":"2021-04-13T19:24:01.624279","exception":false,"start_time":"2021-04-13T19:24:01.345367","status":"completed"},"tags":[],"id":"AUNKeXFWRDmv"}},{"cell_type":"code","source":["class SymmetricCrossEntropy(nn.Module):\n","\n","    def __init__(self, classes=5, alpha=0.1, beta=1.0):\n","        super(SymmetricCrossEntropy, self).__init__()\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.classes = classes\n","\n","    def forward(self, logits, targets, reduction='mean'):\n","        onehot_targets = torch.eye(self.classes)[targets].cuda()\n","        ce_loss = F.cross_entropy(logits, targets, reduction=reduction)\n","        rce_loss = (-onehot_targets*logits.softmax(1).clamp(1e-7, 1.0).log()).sum(1)\n","        if reduction == 'mean':\n","            rce_loss = rce_loss.mean()\n","        elif reduction == 'sum':\n","            rce_loss = rce_loss.sum()\n","        return self.alpha * ce_loss + self.beta * rce_loss"],"metadata":{"papermill":{"duration":0.304593,"end_time":"2021-04-13T19:24:02.208932","exception":false,"start_time":"2021-04-13T19:24:01.904339","status":"completed"},"tags":[],"id":"bbSHmgHgRDmv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LabelSmoothingLoss(nn.Module): \n","    def __init__(self, classes=5, smoothing=0.0, dim=-1): \n","        super(LabelSmoothingLoss, self).__init__() \n","        self.confidence = 1.0 - smoothing \n","        self.smoothing = smoothing \n","        self.classes = classes \n","        self.dim = dim \n","    def forward(self, pred, target): \n","        pred = pred.log_softmax(dim=self.dim) \n","        with torch.no_grad():\n","            true_dist = torch.zeros_like(pred) \n","            true_dist.fill_(self.smoothing / (self.classes - 1)) \n","            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n","        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"],"metadata":{"papermill":{"duration":0.297601,"end_time":"2021-04-13T19:24:02.782359","exception":false,"start_time":"2021-04-13T19:24:02.484758","status":"completed"},"tags":[],"id":"h4oBaqNjRDmv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=1, gamma=5, reduce=True):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.reduce = reduce\n","\n","    def forward(self, inputs, targets):\n","        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n","\n","        pt = torch.exp(-BCE_loss)\n","        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n","\n","        if self.reduce:\n","            return torch.mean(F_loss)\n","        else:\n","            return F_loss"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FocalCosineLoss(nn.Module):\n","    def __init__(self, alpha=1, gamma=2, xent=.1):\n","        super(FocalCosineLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.xent = xent\n","        self.y = torch.Tensor([1]).cuda()\n","    def forward(self, input, target, reduction=\"mean\"):\n","        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=reduction)\n","        cent_loss = F.cross_entropy(F.normalize(input), target, reduce=False)\n","        pt = torch.exp(-cent_loss)\n","        focal_loss = self.alpha * (1-pt)**self.gamma * cent_loss\n","        if reduction == \"mean\":\n","            focal_loss = torch.mean(focal_loss)\n","        return cosine_loss + self.xent * focal_loss"],"metadata":{"id":"DvxTnmvORDmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TaylorSoftmax(nn.Module):\n","    '''\n","    This is the autograd version\n","    '''\n","    def __init__(self, dim=1, n=2):\n","        super(TaylorSoftmax, self).__init__()\n","        assert n % 2 == 0\n","        self.dim = dim\n","        self.n = n\n","\n","    def forward(self, x):\n","        '''\n","        usage similar to nn.Softmax:\n","            >>> mod = TaylorSoftmax(dim=1, n=4)\n","            >>> inten = torch.randn(1, 32, 64, 64)\n","            >>> out = mod(inten)\n","        '''\n","        fn = torch.ones_like(x)\n","        denor = 1.\n","        for i in range(1, self.n+1):\n","            denor *= i\n","            fn = fn + x.pow(i) / denor\n","        out = fn / fn.sum(dim=self.dim, keepdims=True)\n","        return out\n"],"metadata":{"id":"YIRrEVVzRR3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TaylorCrossEntropyLoss(nn.Module):\n","    def __init__(self, n=2, ignore_index=-1, reduction='mean', smoothing=0.0):\n","        super(TaylorCrossEntropyLoss, self).__init__()\n","        assert n % 2 == 0\n","        self.taylor_softmax = TaylorSoftmax(dim=1, n=n)\n","        self.reduction = reduction\n","        self.ignore_index = ignore_index\n","        self.lab_smooth = LabelSmoothingLoss(5, smoothing=smoothing)\n","\n","    def forward(self, logits, labels):\n","        log_probs = self.taylor_softmax(logits).log()\n","        #loss = F.nll_loss(log_probs, labels, reduction=self.reduction,\n","        #        ignore_index=self.ignore_index)\n","        loss = self.lab_smooth(log_probs, labels)\n","        return loss"],"metadata":{"id":"cjTChqXbRWPx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Helper functions"],"metadata":{"papermill":{"duration":0.797804,"end_time":"2021-04-13T19:24:03.947579","exception":false,"start_time":"2021-04-13T19:24:03.149775","status":"completed"},"tags":[],"id":"pV1hj22cRDmw"}},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    \"\"\"\n","    Return average loss for training set in an epoch\n","    \"\"\" \n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    \n","    # switch to train mode\n","    model.train()\n","    start = end = time.time()\n","    global_step = 0\n","    \n","    for step, (images, labels) in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        \n","        # move data to GPU\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        \n","        # forward pass: compute predicted y by passing x to the model. \n","        # Module object overrides the __call__ operator so you can call them like functions\n","        # When doing so you pass a Tensor of input data to the Module and it produces a Tensor of output data\n","        y_preds = model(images)\n","        \n","        # expect as input raw, unnormalized score for each class\n","        loss = criterion(y_preds, labels)\n","        \n","        # loss.item() return the value of this tensor as a python float\n","        losses.update(loss.item(), batch_size)\n","        \n","        # backward pass: compute gradient of the loss wrt all learnable parameters\n","        loss.backward()\n","            \n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        \n","        # call the step function makes an update to its parameters   \n","        optimizer.step()\n","        # zero the gradients before running backward pass on a new epoch\n","        # pytorch accumulate the gradient on subsequent backward passes (convinent for recurrent neural networks)\n","        optimizer.zero_grad()\n","        global_step += 1\n","        \n","        if CFG.scheduler == 'ReduceLROnPlateau':\n","            curr_lr = optimizer.param_groups[0]['lr']\n","        else:\n","            curr_lr = scheduler.get_last_lr()[0]\n","        \n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Batch (curr/avg): ({batch_time.val:.3f}s/{batch_time.avg:.3f}s) '\n","                  'Elapsed {remain:s} '\n","                  'Loss (curr/avg): ({loss.val:.4f}/{loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.6f}  '\n","                  .format(\n","                      epoch+1, step, len(train_loader), \n","                      batch_time=batch_time,\n","                      remain=timeSince(start, float(step+1)/len(train_loader)),\n","                      loss=losses,\n","                      grad_norm=grad_norm,\n","                      lr=curr_lr\n","                   ))\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    \"\"\"\n","    Return the average loss and the list of prediction probabilities for validation set in an epoch\n","    \"\"\"\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    \n","    # switch to evaluation mode\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    \n","    for step, (images, labels) in enumerate(valid_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        # don't compute gradient for validation set (saves memory)\n","        with torch.no_grad():\n","            y_preds = model(images)\n","        loss = criterion(y_preds, labels)\n","        losses.update(loss.item(), batch_size)\n","        \n","        preds.append(y_preds.softmax(1).detach().to('cpu').numpy())\n","            \n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Batch (curr/avg): ({batch_time.val:.3f}s/{batch_time.avg:.3f}s) '\n","                  'Elapsed {remain:s} '\n","                  'Loss (curr/avg): ({loss.val:.4f}/{loss.avg:.4f}) '\n","                  .format(\n","                      step, len(valid_loader),\n","                      batch_time=batch_time,\n","                      remain=timeSince(start, float(step+1)/len(valid_loader)),\n","                      loss=losses\n","                   ))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions\n","\n","\n","def get_loaders(folds, fold):\n","    \"\"\"\n","    Return training dataset and data loader, validation dataset and data loader \n","    \"\"\" \n","    trn_idx = folds[folds['fold'] != fold].index\n","    val_idx = folds[folds['fold'] == fold].index\n","\n","    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n","    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = TrainDataset(train_folds, \n","                                 transform=get_transforms(data='train'))\n","    valid_dataset = TrainDataset(valid_folds, \n","                                 transform=get_transforms(data='valid'))\n","\n","    # setting pin_memory to True enables fast data transfer to CUDA-enabled GPUs\n","    # set drop_last to True to disgard last incomplete batch\n","    train_loader = DataLoader(train_dataset, \n","                              batch_size=CFG.batch_size, \n","                              shuffle=True, \n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset, \n","                              batch_size=CFG.batch_size, \n","                              shuffle=False, \n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","    return train_folds, train_loader, valid_folds, valid_loader\n","    \n","\n","def get_model(pretrained=True):\n","    \"\"\"\n","    Get pretrained model\n","    \"\"\"\n","    if CFG.model_name=='resnext50_32x4d':\n","        model = CustomResNext(pretrained=pretrained)\n","    elif  CFG.model_name=='tf_efficientnet_b3_ns':\n","        model = CustomEfficientNet(pretrained=pretrained)\n","    elif CFG.model_name=='deit_base_patch16_224':\n","        model = CustomDeit(pretrained=pretrained)\n","    elif CFG.model_name=='vit_base_patch16_224' or CFG.model_name=='vit_small_patch16_224':\n","        model = CustomDeit(pretrained=pretrained)\n","    return model\n","\n","\n","def get_optimizer(model_params):\n","    \"\"\"\n","    Get optimizer\n","    \"\"\"\n","    if CFG.optimizer=='Adam':\n","        optimizer =  Adam(model_params, lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    elif CFG.optimizer=='AdamW':\n","        optimizer =  Adam(model_params, lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    elif CFG.optimizer=='AdamP':\n","        optimizer =  Adam(model_params, lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    elif CFG.optimizer=='Ranger':\n","        optimizer = Ranger(model_params, lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    return optimizer\n","\n","    \n","def get_scheduler(optimizer):\n","    \"\"\"\n","    Get learning rate scheduler\n","    \"\"\"\n","    if CFG.scheduler=='ReduceLROnPlateau':\n","        scheduler = ReduceLROnPlateau(optimizer, factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n","    elif CFG.scheduler=='CosineAnnealingLR':\n","        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n","    elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n","        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n","    return scheduler\n","\n","\n","def get_criterion():\n","    \"\"\"\n","    Get loss function\n","    \"\"\"\n","    if CFG.criterion=='CrossEntropyLoss':\n","        criterion = nn.CrossEntropyLoss()\n","    elif CFG.criterion=='SymmetricCrossEntropyLoss':\n","        criterion = SymmetricCrossEntropy()\n","    elif CFG.criterion=='LabelSmoothingLoss':\n","        criterion = LabelSmoothingLoss(smoothing=CFG.smoothing)\n","    elif CFG.criterion=='FocalCosineLoss':\n","        criterion = FocalCosineLoss()\n","    elif CFG.criterion=='TaylorCrossEntropyLoss':\n","        criterion = TaylorCrossEntropyLoss(smoothing=CFG.smoothing)\n","    return criterion\n","    \n","    \n","def inference(model, states, test_loader, device):\n","    model.to(device)\n","    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n","    probs = []\n","    for i, (images) in tk0:\n","        images = images.to(device)\n","        avg_preds = []\n","        for state in states:\n","            model.load_state_dict(state['model'])\n","            model.eval()\n","            with torch.no_grad():\n","                y_preds = model(images)\n","            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n","        avg_preds = np.mean(avg_preds, axis=0)\n","        probs.append(avg_preds)\n","    probs = np.concatenate(probs)\n","    return probs\n","\n","\n","def inference_tta(model, states, test_loader, device):\n","    model.to(device)\n","    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n","    probs = []\n","    for i, (images) in tk0:\n","        x = images.to(device)\n","        x = torch.stack([x, x.flip(-1), x.flip(-2), x.flip(-1,-2),\n","                         x.transpose(-1,-2), x.transpose(-1,-2).flip(-1),\n","                         x.transpose(-1,-2).flip(-2),x.transpose(-1,-2).flip(-1,-2)], 0)\n","        # reshape tension\n","        x = x.view(-1, 3, CFG.size, CFG.size)\n","        avg_preds = []\n","        for state in states:\n","            model.load_state_dict(state['model'])\n","            model.eval()\n","            with torch.no_grad():\n","                y_preds = model(x)\n","            y_preds = y_preds.view(1, 8, 5).mean(axis=1)\n","            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n","        avg_preds = np.mean(avg_preds, axis=0)\n","        probs.append(avg_preds)\n","    probs = np.concatenate(probs)\n","    return probs"],"metadata":{"papermill":{"duration":0.346351,"end_time":"2021-04-13T19:24:04.580164","exception":false,"start_time":"2021-04-13T19:24:04.233813","status":"completed"},"tags":[],"id":"iQUTHWZVRDmx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train loop"],"metadata":{"papermill":{"duration":0.280407,"end_time":"2021-04-13T19:24:05.141191","exception":false,"start_time":"2021-04-13T19:24:04.860784","status":"completed"},"tags":[],"id":"ecGS1VsSRDm3"}},{"cell_type":"code","source":["# ====================================================\n","# Train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds, train_loader, valid_folds, valid_loader = get_loaders(folds, fold)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = get_model(pretrained=True)\n","    # move model to GPU\n","    model.to(device)\n","\n","    optimizer = get_optimizer(model.parameters())\n","    scheduler = get_scheduler(optimizer)\n","    criterion = get_criterion()\n","    \n","    # ====================================================\n","    # loop\n","    # ====================================================\n","\n","    best_score = 0.\n","    best_loss = np.inf\n","    \n","    for epoch in range(CFG.epochs):\n","        \n","        start_time = time.time()\n","        \n","        # train\n","        avg_train_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","        \n","        # eval\n","        avg_val_loss, val_preds = valid_fn(valid_loader, model, criterion, device)\n","        valid_labels = valid_folds['label'].values\n","        \n","        if isinstance(scheduler, ReduceLROnPlateau):\n","            scheduler.step(avg_val_loss)\n","        elif isinstance(scheduler, CosineAnnealingLR):\n","            scheduler.step()\n","        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n","            scheduler.step()\n","\n","        # scoring\n","        val_score = get_score(valid_labels, val_preds.argmax(1))\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - val_accuracy: {val_score:.4f}')\n","\n","        if val_score > best_score:\n","            best_score = val_score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(), \n","                        'preds': val_preds},\n","                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n","    \n","    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n","    valid_folds[[str(c) for c in range(5)]] = check_point['preds']\n","    valid_folds['preds'] = check_point['preds'].argmax(1)\n","\n","    return valid_folds"],"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.3256,"end_time":"2021-04-13T19:24:05.772386","exception":false,"start_time":"2021-04-13T19:24:05.446786","status":"completed"},"tags":[],"id":"CAvJaxvNRDm6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# main\n","# ====================================================\n","def main():\n","\n","    \"\"\"\n","    Prepare: 1.train  2.test  3.submission  4.folds\n","    \"\"\"\n","\n","    def get_result(result_df):\n","        preds = result_df['preds'].values\n","        labels = result_df['label'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.5f}')\n","    \n","    if CFG.train:\n","        # train \n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(folds, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        # CV result\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        # save result\n","        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n","    \n","    if CFG.inference:\n","        # validation set\n","#         test_dataset = TestDataset(val, transform=get_transforms(data='valid'))\n","        \n","        # test submission\n","        test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n","\n","        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, \n","                                 num_workers=CFG.num_workers, pin_memory=True)\n"," \n","        # ResNext\n","        model = CustomResNext(pretrained=False)\n","        states = [torch.load(OUTPUT_PATH+f'{CFG.model_name}_fold{fold}_best.pth') for fold in CFG.trn_fold]\n","        predictions = inference(model, states, test_loader, device)\n","        \n","        # EfficientNet with TTA\n","        enet = CustomEfficientNet(model=CFG.enet_name, pretrained=False)\n","        enet_states = [torch.load(OUTPUT_PATH+f'{CFG.enet_name}_fold{fold}_best.pth') for fold in CFG.enet_weights]\n","#         predictions_no_tta = inference(enet, enet_states, test_loader, device)\n","        predictions2 = inference_tta(enet, enet_states, test_loader, device)\n","\n","        pred = 0.5 * predictions + 0.5 * predictions2\n","#         valid_labels = val['label'].values\n","#         ent_score = get_score(valid_labels, predictions_no_tta.argmax(1))\n","#         print('EfficientNet accuracy: {:.4f}'.format(ent_score))\n","#         ent_score_tta = get_score(valid_labels, predictions2.argmax(1))\n","#         print('EfficientNet with TTA accuracy: {:.4f}'.format(ent_score_tta))\n","#         resnext_score = get_score(valid_labels, predictions.argmax(1))\n","#         print('ResNext accuracy: {:.4f}'.format(resnext_score))\n","#         ensemble_score = get_score(valid_labels, pred.argmax(1))\n","#         print('Ensemble accuracy: {:.4f}'.format(ensemble_score))\n","        \n","        # submission\n","        test['label'] = pred.argmax(1)\n","        print(test[['image_id', 'label']])\n","        test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)"],"metadata":{"papermill":{"duration":0.305496,"end_time":"2021-04-13T19:24:06.357516","exception":false,"start_time":"2021-04-13T19:24:06.05202","status":"completed"},"tags":[],"id":"9rhmBEnsRDm6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    main()"],"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":9.750104,"end_time":"2021-04-13T19:24:16.385774","exception":false,"start_time":"2021-04-13T19:24:06.63567","status":"completed"},"tags":[],"id":"JpkvRyydRDm7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"papermill":{"duration":0.284776,"end_time":"2021-04-13T19:24:16.954604","exception":false,"start_time":"2021-04-13T19:24:16.669828","status":"completed"},"tags":[],"id":"U9DSgerORDm7"},"execution_count":null,"outputs":[]}]}